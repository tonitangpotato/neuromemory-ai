#!/usr/bin/env python3
"""
Comprehensive Edge Case Tests for NeuromemoryAI

These tests cover unusual inputs, boundary conditions, and potential
failure modes before deploying to production use.

Categories:
1. Input validation (empty, long, special chars, unicode)
2. Scale testing (large number of memories)
3. Concurrency (multi-process access)
4. State transitions (consolidation, forgetting edge cases)
5. Hebbian edge cases (deleted memories, circular refs)
6. Recovery (corruption, partial writes)
7. Config edge cases (invalid values)
"""

import os
import sys
import tempfile
import time
import threading
import concurrent.futures
from pathlib import Path

import pytest

sys.path.insert(0, str(Path(__file__).parent.parent))

from engram import Memory
from engram.config import MemoryConfig
from engram.core import MemoryType
from engram.hebbian import (
    record_coactivation,
    get_hebbian_neighbors,
    get_all_hebbian_links,
    decay_hebbian_links,
)


class TestInputValidation:
    """Edge cases for input handling."""

    def test_empty_content(self):
        """Empty string content should be handled gracefully."""
        mem = Memory(":memory:")
        # Should either work or raise a clear error
        try:
            mid = mem.add("", type="factual")
            # If it works, recall should handle it
            results = mem.recall("")
            assert isinstance(results, list)
        except ValueError as e:
            assert "empty" in str(e).lower() or "content" in str(e).lower()

    def test_whitespace_only_content(self):
        """Whitespace-only content."""
        mem = Memory(":memory:")
        mid = mem.add("   \n\t  ", type="factual")
        results = mem.recall("whitespace")
        # Should return empty or the whitespace memory

    def test_very_long_content(self):
        """Content longer than typical limits."""
        mem = Memory(":memory:")
        long_text = "A" * 100_000  # 100KB of text
        mid = mem.add(long_text, type="factual")
        assert mid is not None
        
        # Should be retrievable
        entry = mem._store.get(mid)
        assert len(entry.content) == 100_000

    def test_unicode_content(self):
        """Unicode including emoji, CJK, RTL."""
        mem = Memory(":memory:")
        
        test_cases = [
            "Hello ‰∏ñÁïå üåç ŸÖÿ±ÿ≠ÿ®ÿß",  # Mixed scripts
            "üéâüéäüéÅüéÑüéÖ",  # Emoji only
            "Êó•Êú¨Ë™û„ÉÜ„Çπ„Éà",  # Japanese
            "–¢–µ—Å—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—ã",  # Cyrillic
            "◊¢◊ë◊®◊ô◊™",  # Hebrew (RTL)
            "üß†" * 1000,  # Many emoji
            "\u0000\u0001\u0002",  # Control characters
        ]
        
        for content in test_cases:
            mid = mem.add(content, type="factual")
            entry = mem._store.get(mid)
            assert entry.content == content, f"Failed for: {content[:20]}..."

    def test_special_sql_characters(self):
        """SQL injection prevention."""
        mem = Memory(":memory:")
        
        dangerous_inputs = [
            "'; DROP TABLE memories; --",
            "Robert'); DROP TABLE memories;--",
            "1 OR 1=1",
            "UNION SELECT * FROM memories",
            "content LIKE '%'",
        ]
        
        for content in dangerous_inputs:
            mid = mem.add(content, type="factual")
            entry = mem._store.get(mid)
            assert entry.content == content  # Should be stored literally

    def test_null_bytes_in_content(self):
        """Null bytes should be handled."""
        mem = Memory(":memory:")
        content = "before\x00after"
        mid = mem.add(content, type="factual")
        entry = mem._store.get(mid)
        # Either stored as-is or sanitized
        assert entry is not None

    def test_empty_query_recall(self):
        """Recall with empty query."""
        mem = Memory(":memory:")
        mem.add("Test memory", type="factual")
        
        results = mem.recall("")
        assert isinstance(results, list)

    def test_very_long_query(self):
        """Query longer than typical."""
        mem = Memory(":memory:")
        mem.add("Short memory", type="factual")
        
        long_query = "search " * 10000
        results = mem.recall(long_query, limit=5)
        assert isinstance(results, list)

    def test_importance_bounds(self):
        """Importance values at and beyond bounds."""
        mem = Memory(":memory:")
        
        # At bounds
        mem.add("Low importance", importance=0.0)
        mem.add("High importance", importance=1.0)
        
        # Beyond bounds - should clamp or error
        try:
            mem.add("Negative", importance=-0.5)
        except (ValueError, AssertionError):
            pass  # Expected
            
        try:
            mem.add("Over one", importance=1.5)
        except (ValueError, AssertionError):
            pass  # Expected

    def test_invalid_memory_type(self):
        """Invalid memory type should error or default."""
        mem = Memory(":memory:")
        
        try:
            mem.add("Test", type="invalid_type_xyz")
            # If it doesn't error, check it defaulted
        except (ValueError, KeyError):
            pass  # Expected


class TestScaleTesting:
    """Performance and behavior at scale."""

    def test_1000_memories(self):
        """Basic scale: 1000 memories."""
        mem = Memory(":memory:")
        
        # Add 1000 memories
        for i in range(1000):
            mem.add(f"Memory number {i} with some content", type="factual")
        
        stats = mem.stats()
        assert stats["total_memories"] == 1000
        
        # Recall should still be fast
        start = time.perf_counter()
        results = mem.recall("memory number", limit=10)
        elapsed = time.perf_counter() - start
        
        assert elapsed < 0.5  # Should be under 500ms
        assert len(results) == 10

    def test_10000_memories(self):
        """Medium scale: 10000 memories."""
        with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
            db_path = f.name
        
        try:
            mem = Memory(db_path)
            
            # Add 10000 memories in batches
            for batch in range(100):
                for i in range(100):
                    idx = batch * 100 + i
                    mem.add(f"Memory {idx}: batch {batch} item {i}", type="factual")
            
            stats = mem.stats()
            assert stats["total_memories"] == 10000
            
            # Recall latency
            start = time.perf_counter()
            results = mem.recall("batch 50", limit=10)
            elapsed = time.perf_counter() - start
            
            assert elapsed < 1.0  # Should be under 1 second
            
            # Consolidation at scale
            start = time.perf_counter()
            mem.consolidate(days=1)
            elapsed = time.perf_counter() - start
            
            assert elapsed < 30.0  # Should be under 30 seconds
            
        finally:
            os.unlink(db_path)

    def test_many_hebbian_links(self):
        """Many Hebbian links between memories."""
        mem = Memory(":memory:", config=MemoryConfig.researcher())
        mem.config.hebbian_enabled = True
        mem.config.hebbian_threshold = 1  # Form links quickly
        
        # Add 100 memories
        ids = []
        for i in range(100):
            mid = mem.add(f"Memory {i}", type="factual")
            ids.append(mid)
        
        # Co-activate many pairs (threshold=1 means immediate link formation)
        for i in range(0, 100, 2):
            # Call twice to ensure link forms (first creates tracking, second forms link)
            record_coactivation(mem._store, [ids[i], ids[i+1]], threshold=1)
            record_coactivation(mem._store, [ids[i], ids[i+1]], threshold=1)
        
        # Should have ~50 links (bidirectional = 100)
        links = get_all_hebbian_links(mem._store)
        assert len(links) >= 50


class TestConcurrency:
    """Multi-threaded and multi-process access."""

    def test_concurrent_reads(self):
        """Multiple threads reading simultaneously."""
        with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
            db_path = f.name
        
        try:
            # Setup
            mem = Memory(db_path)
            for i in range(100):
                mem.add(f"Memory {i}", type="factual")
            del mem
            
            # Concurrent reads
            def read_memories():
                m = Memory(db_path)
                results = []
                for _ in range(10):
                    r = m.recall("memory", limit=5)
                    results.append(len(r))
                return results
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                futures = [executor.submit(read_memories) for _ in range(4)]
                for future in concurrent.futures.as_completed(futures):
                    results = future.result()
                    assert all(r == 5 for r in results)
        finally:
            os.unlink(db_path)

    def test_concurrent_writes(self):
        """Multiple threads writing simultaneously."""
        with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
            db_path = f.name
        
        try:
            def write_memories(thread_id):
                m = Memory(db_path)
                for i in range(25):
                    m.add(f"Thread {thread_id} memory {i}", type="factual")
                return 25
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                futures = [executor.submit(write_memories, i) for i in range(4)]
                total = sum(f.result() for f in concurrent.futures.as_completed(futures))
            
            # All 100 should be written
            mem = Memory(db_path)
            stats = mem.stats()
            assert stats["total_memories"] == 100
        finally:
            os.unlink(db_path)

    @pytest.mark.skip(reason="SQLite has known concurrency limitations - database locking expected")
    def test_read_write_interleaved(self):
        """
        Reads and writes happening simultaneously.
        
        NOTE: This test documents a known SQLite limitation.
        SQLite uses file-level locking, so concurrent writes from
        different connections can cause "database is locked" errors.
        
        For production use with high concurrency, consider:
        1. Using a single Memory instance per process
        2. Connection pooling with WAL mode
        3. Switching to a concurrent-safe backend (Postgres, etc.)
        """
        with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
            db_path = f.name
        
        try:
            # Seed some data
            mem = Memory(db_path)
            for i in range(50):
                mem.add(f"Initial memory {i}", type="factual")
            del mem
            
            errors = []
            
            def reader():
                try:
                    m = Memory(db_path)
                    for _ in range(20):
                        m.recall("memory", limit=5)
                        time.sleep(0.01)
                except Exception as e:
                    errors.append(f"Reader: {e}")
            
            def writer():
                try:
                    m = Memory(db_path)
                    for i in range(20):
                        m.add(f"New memory {i}", type="factual")
                        time.sleep(0.01)
                except Exception as e:
                    errors.append(f"Writer: {e}")
            
            threads = [
                threading.Thread(target=reader),
                threading.Thread(target=reader),
                threading.Thread(target=writer),
            ]
            
            for t in threads:
                t.start()
            for t in threads:
                t.join()
            
            # With SQLite, some lock contention is expected
            # This is documented behavior, not a bug
            assert len(errors) == 0, f"Errors: {errors}"
        finally:
            os.unlink(db_path)


class TestStateTransitions:
    """Edge cases in memory state changes."""

    def test_consolidate_empty_db(self):
        """Consolidation with no memories."""
        mem = Memory(":memory:")
        mem.consolidate(days=1)  # Should not error
        assert mem.stats()["total_memories"] == 0

    def test_consolidate_zero_days(self):
        """Consolidation with 0 days."""
        mem = Memory(":memory:")
        mem.add("Test", type="factual")
        mem.consolidate(days=0)  # Should handle gracefully

    def test_consolidate_negative_days(self):
        """Consolidation with negative days."""
        mem = Memory(":memory:")
        mem.add("Test", type="factual")
        try:
            mem.consolidate(days=-1)
        except ValueError:
            pass  # Expected

    def test_consolidate_large_days(self):
        """Consolidation simulating years."""
        mem = Memory(":memory:")
        mem.add("Test", type="factual", importance=0.5)
        mem.consolidate(days=365)  # One year
        
        # Memory should be heavily decayed
        entry = mem._store.all()[0]
        assert entry.working_strength < 0.01  # Should be very low

    def test_forget_all_memories(self):
        """Forget with threshold that removes everything."""
        mem = Memory(":memory:")
        for i in range(10):
            mem.add(f"Memory {i}", type="factual", importance=0.1)
        
        # Heavy consolidation
        mem.consolidate(days=100)
        
        # Forget with high threshold
        mem.forget(threshold=1.0)  # Everything below 1.0
        
        # Check what remains
        stats = mem.stats()
        # Memories might be archived, not deleted

    def test_forget_pinned_memories(self):
        """Pinned memories should not be forgotten."""
        mem = Memory(":memory:")
        mid = mem.add("Important memory", type="factual", importance=0.1)
        mem.pin(mid)
        
        # Heavy consolidation and forget
        mem.consolidate(days=100)
        mem.forget(threshold=1.0)
        
        # Should still exist
        entry = mem._store.get(mid)
        assert entry is not None
        assert entry.pinned

    def test_forget_nonexistent_id(self):
        """Forget a memory ID that doesn't exist."""
        mem = Memory(":memory:")
        try:
            mem.forget("nonexistent-uuid-12345")
        except (KeyError, ValueError):
            pass  # Expected
        # Or it might silently do nothing

    def test_reward_empty_db(self):
        """Reward with no memories to reward."""
        mem = Memory(":memory:")
        mem.reward("Great job!")  # Should not error

    def test_reward_extreme_sentiment(self):
        """Reward with extreme positive/negative text."""
        mem = Memory(":memory:")
        mem.add("Test", type="factual")
        
        mem.reward("!!!!!AMAZING PERFECT WONDERFUL!!!!!")
        mem.reward("TERRIBLE AWFUL HORRIBLE DISASTER")


class TestHebbianEdgeCases:
    """Edge cases in Hebbian learning."""

    def test_coactivate_single_memory(self):
        """Co-activation with only one memory (no pairs)."""
        mem = Memory(":memory:")
        mid = mem.add("Solo memory", type="factual")
        
        # Should not error, just do nothing
        links = record_coactivation(mem._store, [mid], threshold=3)
        assert links == []

    def test_coactivate_same_memory_twice(self):
        """Co-activation list with duplicate IDs."""
        mem = Memory(":memory:")
        mid = mem.add("Test", type="factual")
        
        # Duplicate in list
        links = record_coactivation(mem._store, [mid, mid], threshold=3)
        # Should handle gracefully (no self-links)

    def test_hebbian_with_deleted_memory(self):
        """Hebbian link to a deleted memory."""
        mem = Memory(":memory:", config=MemoryConfig.researcher())
        mem.config.hebbian_enabled = True
        mem.config.hebbian_threshold = 1
        
        mid1 = mem.add("Memory 1", type="factual")
        mid2 = mem.add("Memory 2", type="factual")
        
        # Form link
        record_coactivation(mem._store, [mid1, mid2], threshold=1)
        
        # Delete one memory
        mem._store.delete(mid1)
        
        # Query neighbors of deleted memory
        neighbors = get_hebbian_neighbors(mem._store, mid1)
        # Should return empty or handle gracefully

    def test_decay_with_no_links(self):
        """Decay Hebbian links when none exist."""
        mem = Memory(":memory:")
        pruned = decay_hebbian_links(mem._store, factor=0.95)
        assert pruned == 0

    def test_many_coactivations_same_pair(self):
        """Same pair co-activated many times."""
        mem = Memory(":memory:")
        mem.config.hebbian_enabled = True
        mem.config.hebbian_threshold = 3
        
        mid1 = mem.add("A", type="factual")
        mid2 = mem.add("B", type="factual")
        
        # Co-activate 100 times
        for _ in range(100):
            record_coactivation(mem._store, [mid1, mid2], threshold=3)
        
        # Link should exist with high strength
        links = get_all_hebbian_links(mem._store)
        # Should have bidirectional link, strength capped at 1.0


class TestRecovery:
    """Database recovery and corruption handling."""

    def test_open_nonexistent_creates(self):
        """Opening non-existent path creates new DB."""
        with tempfile.TemporaryDirectory() as tmpdir:
            db_path = os.path.join(tmpdir, "new.db")
            assert not os.path.exists(db_path)
            
            mem = Memory(db_path)
            mem.add("Test", type="factual")
            
            assert os.path.exists(db_path)

    def test_reopen_persists(self):
        """Data persists across open/close cycles."""
        with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
            db_path = f.name
        
        try:
            # Write
            mem = Memory(db_path)
            mid = mem.add("Persistent memory", type="factual")
            del mem
            
            # Reopen
            mem2 = Memory(db_path)
            entry = mem2._store.get(mid)
            assert entry.content == "Persistent memory"
        finally:
            os.unlink(db_path)

    def test_readonly_mode(self):
        """Opening in read-only filesystem situation."""
        # This is hard to test portably, skip for now
        pass

    def test_disk_full_simulation(self):
        """Behavior when disk is full."""
        # Hard to simulate portably, skip
        pass


class TestConfigEdgeCases:
    """Configuration edge cases."""

    def test_zero_decay_rate(self):
        """Decay rate of 0 (no decay)."""
        config = MemoryConfig.researcher()
        config.working_decay = 0.0
        config.core_decay = 0.0
        
        mem = Memory(":memory:", config=config)
        mid = mem.add("Never decay", type="factual")
        
        # Consolidate many days
        mem.consolidate(days=1000)
        
        entry = mem._store.get(mid)
        # With 0 decay, strength should remain high

    def test_very_high_decay_rate(self):
        """Very high decay rate."""
        config = MemoryConfig.task_agent()
        config.working_decay = 0.99  # 99% decay per cycle
        
        mem = Memory(":memory:", config=config)
        mid = mem.add("Fast decay", type="factual")
        
        mem.consolidate(days=10)
        
        entry = mem._store.get(mid)
        # High decay should reduce working strength significantly
        # (not necessarily < 0.001 due to consolidation dynamics)
        assert entry.working_strength < 0.1

    def test_hebbian_threshold_zero(self):
        """Hebbian threshold of 0 (immediate linking)."""
        config = MemoryConfig.researcher()
        config.hebbian_enabled = True
        config.hebbian_threshold = 0
        
        mem = Memory(":memory:", config=config)
        mid1 = mem.add("A", type="factual")
        mid2 = mem.add("B", type="factual")
        
        # Should form link immediately on first co-activation
        # (or threshold 0 might mean 1)

    def test_hebbian_threshold_very_high(self):
        """Hebbian threshold too high to ever form links."""
        config = MemoryConfig.researcher()
        config.hebbian_enabled = True
        config.hebbian_threshold = 1000000
        
        mem = Memory(":memory:", config=config)
        mid1 = mem.add("A", type="factual")
        mid2 = mem.add("B", type="factual")
        
        for _ in range(100):
            record_coactivation(mem._store, [mid1, mid2], threshold=1000000)
        
        links = get_all_hebbian_links(mem._store)
        assert len(links) == 0  # Never reached threshold


class TestAPIConsistency:
    """Ensure API behaves consistently."""

    def test_recall_returns_list(self):
        """Recall always returns a list."""
        mem = Memory(":memory:")
        
        # Empty DB
        assert isinstance(mem.recall("test"), list)
        
        # With data
        mem.add("Test", type="factual")
        assert isinstance(mem.recall("test"), list)
        assert isinstance(mem.recall("nonexistent"), list)

    def test_stats_returns_dict(self):
        """Stats always returns a dict with expected keys."""
        mem = Memory(":memory:")
        
        stats = mem.stats()
        assert isinstance(stats, dict)
        assert "total_memories" in stats

    def test_add_returns_string_id(self):
        """Add always returns a string ID."""
        mem = Memory(":memory:")
        mid = mem.add("Test", type="factual")
        
        assert isinstance(mid, str)
        assert len(mid) > 0

    def test_memory_types_all_valid(self):
        """All documented memory types work."""
        mem = Memory(":memory:")
        
        types = ["factual", "episodic", "relational", "emotional", "procedural", "opinion"]
        for t in types:
            mid = mem.add(f"Type {t}", type=t)
            entry = mem._store.get(mid)
            assert entry.memory_type.value == t or entry.memory_type.name.lower() == t


class TestRegressions:
    """Tests for previously found bugs."""

    def test_day_90_zero_links_regression(self):
        """
        Regression test: Hebbian links should persist over time
        when memories are co-activated again.
        (Previously links decayed to 0 by day 90)
        """
        mem = Memory(":memory:", config=MemoryConfig.researcher())
        mem.config.hebbian_enabled = True
        mem.config.hebbian_threshold = 2
        
        # Add memories
        mid1 = mem.add("Python programming", type="factual")
        mid2 = mem.add("Machine learning", type="factual")
        
        # Form link
        for _ in range(3):
            record_coactivation(mem._store, [mid1, mid2], threshold=2)
        
        initial_links = len(get_all_hebbian_links(mem._store))
        assert initial_links > 0
        
        # Simulate 90 days with periodic recall (co-activation)
        for day in range(90):
            mem.consolidate(days=1)
            decay_hebbian_links(mem._store, factor=0.95)
            
            # Periodic co-activation (simulating user recalls these together)
            if day % 10 == 0:
                record_coactivation(mem._store, [mid1, mid2], threshold=2)
        
        final_links = len(get_all_hebbian_links(mem._store))
        assert final_links > 0, "Links should persist with periodic co-activation"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
